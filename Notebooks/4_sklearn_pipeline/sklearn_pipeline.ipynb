{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fffd8c-9192-46d7-ad8c-520967341e42",
   "metadata": {},
   "source": [
    "## A Sklearn pipeline\n",
    "A sklearn pipeline for a small datset that transforms numerical and categorical columns and standardize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49e1d85-0ab8-4c2a-8615-fd9b134ea093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "Model saved as 'pipe.joblib'\n",
      "Loaded model successfully.\n",
      "Loaded pipeline verification score: 1.0\n",
      "Predictions: [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script addresses the problem of classifying music events into 'sold-out' or 'not sold-out' categories \n",
    "based on various features such as genre, social media followers, and likes. The pipeline involves data \n",
    "preprocessing, including handling missing values, scaling numerical features, and encoding categorical data.\n",
    "A decision tree classifier is trained on the processed data, and the resulting model is saved for future use.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import joblib\n",
    "from typing import Tuple, Optional \n",
    "\n",
    "def create_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame with sample data for a music genre classification task.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with music genres, social media followers, likes, and sold-out status.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'Genre': ['Rock', 'Metal', 'Bluegrass', 'Rock', np.nan, 'Rock', 'Rock', np.nan, 'Bluegrass', 'Rock'],\n",
    "        'Social_media_followers': [1000000, 1000000, 2000000, 1310000, 1700000, np.nan, 4100000, 1600000, 2200000, 1000000],\n",
    "        'likes': [6000000, 1000000, 5000000, 1610000, 1800000, np.nan, 4800000, 1650000, 2680000, 5000000],\n",
    "        'Sold_out': [1, 1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, ColumnTransformer]:\n",
    "    \"\"\"\n",
    "    Preprocess data by setting up a pipeline with imputation, scaling, and encoding steps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing features and target variable.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: Feature matrix X, target vector y, and ColumnTransformer for preprocessing.\n",
    "    \"\"\"\n",
    "    # Separate features and target variable\n",
    "    X = df.drop(columns='Sold_out')\n",
    "    y = df['Sold_out']\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Define pipelines for numerical and categorical transformations\n",
    "    num_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('scale', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine pipelines using ColumnTransformer\n",
    "    col_trans = ColumnTransformer([\n",
    "        ('num', num_pipe, num_cols),\n",
    "        ('cat', cat_pipe, cat_cols)\n",
    "    ], remainder='drop', n_jobs=-1)\n",
    "\n",
    "    return X, y, col_trans\n",
    "\n",
    "def build_pipeline(col_trans: ColumnTransformer) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a machine learning pipeline with a preprocessor and a decision tree classifier.\n",
    "    \n",
    "    Args:\n",
    "        col_trans (ColumnTransformer): A ColumnTransformer containing preprocessing steps.\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: A machine learning pipeline with preprocessing and a classifier.\n",
    "    \"\"\"\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    pipeline = make_pipeline(col_trans, classifier)\n",
    "    return pipeline\n",
    "\n",
    "def train_and_evaluate(pipeline: Pipeline, X: pd.DataFrame, y: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Train the pipeline on training data, evaluate it on test data, and save the trained model.\n",
    "    \n",
    "    Args:\n",
    "        pipeline (Pipeline): The machine learning pipeline to train and evaluate.\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.Series): Target vector.\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy score on the test set.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        precision = precision_score(y_test, pipeline.predict(X_test),zero_division=0)\n",
    "        recall = recall_score(y_test, pipeline.predict(X_test),zero_division=0)\n",
    "        \n",
    "        print(f'Model Accuracy: {score:.2f}')\n",
    "        print(f'Precision: {precision:.2f}')\n",
    "        print(f'Recall: {recall:.2f}')\n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(pipeline, 'pipe.joblib')\n",
    "        print(\"Model saved as 'pipe.joblib'\")\n",
    "        \n",
    "        return score\n",
    "\n",
    "    except NotFittedError as e:\n",
    "        print(f\"Model not fitted yet: {e}\")\n",
    "        return -1\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError during training: {e}\")\n",
    "        return -1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during training or evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "def load_and_verify_model() -> Optional[Pipeline]:\n",
    "    \"\"\"\n",
    "    Load a previously saved machine learning model from a file and verify its contents.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Pipeline]: The loaded model (Pipeline object) if successful, \n",
    "        or None if there was an error loading the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to load the model from the joblib file\n",
    "        model = joblib.load('pipe.joblib')\n",
    "        print(\"Loaded model successfully.\")\n",
    "        return model\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        # Handle case where the file does not exist\n",
    "        print(f\"Model file not found: {e}\")\n",
    "        return None\n",
    "    \n",
    "    except joblib.exceptions.InvalidFileException as e:\n",
    "        # Handle case where the file is not a valid joblib file\n",
    "        print(f\"Invalid model file: {e}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other unforeseen errors and print the error message\n",
    "        print(f\"An unexpected error occurred while loading the model: {e}\")\n",
    "        return None\n",
    "\n",
    "def make_inference(model: Pipeline, new_data: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make predictions on new data using the trained model pipeline.\n",
    "    \n",
    "    Args:\n",
    "        model (Pipeline): The trained model pipeline.\n",
    "        new_data (pd.DataFrame): A DataFrame containing new data for inference.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Predictions for the new data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Predict using the loaded model\n",
    "        predictions = model.predict(new_data)\n",
    "        print(\"Predictions:\", predictions)\n",
    "        return predictions\n",
    "    \n",
    "    except NotFittedError as e:\n",
    "        print(f\"Model is not fitted: {e}\")\n",
    "        return np.array([])\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError during inference: {e}\")\n",
    "        return np.array([])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during inference: {e}\")\n",
    "        return np.array([])\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to execute the ML pipeline for preprocessing, training, evaluation, and saving the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load data\n",
    "        df = create_dataframe()\n",
    "        \n",
    "        # Step 2: Preprocess data\n",
    "        X, y, col_trans = preprocess_data(df)\n",
    "        \n",
    "        # Step 3: Build pipeline\n",
    "        pipeline = build_pipeline(col_trans)\n",
    "        \n",
    "        # Step 4: Train and evaluate model\n",
    "        score = train_and_evaluate(pipeline, X, y)\n",
    "        \n",
    "        # Step 5: Load and verify saved model\n",
    "        loaded_pipeline = load_and_verify_model()\n",
    "        \n",
    "        # Step 6: Make inference on new data if the model loaded successfully\n",
    "        if loaded_pipeline:\n",
    "            # Example new data for inference\n",
    "            new_data = pd.DataFrame({\n",
    "                'Genre': ['Rock', 'Bluegrass', np.nan],\n",
    "                'Social_media_followers': [1500000, np.nan, 2300000],\n",
    "                'likes': [1800000, 2100000, np.nan]\n",
    "            })\n",
    "            print(\"Loaded pipeline verification score:\", loaded_pipeline.score(X, y))\n",
    "            make_inference(loaded_pipeline, new_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the main function: {e}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
